{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('../data/test.csv',usecols=['srch_id','prop_id','prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "           'prop_location_score1', 'prop_location_score2',\n",
    "           'prop_log_historical_price','srch_destination_id','orig_destination_distance'])\n",
    "dfTrain = pd.read_csv('../data/train.csv',usecols=['srch_id','prop_id','prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "           'prop_location_score1', 'prop_location_score2',\n",
    "           'prop_log_historical_price','srch_destination_id','booking_bool','orig_destination_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "together = pd.concat([dfTest,dfTrain],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTestDist = dfTest[['srch_id','orig_destination_distance']].groupby(['srch_id']).mean()\n",
    "meanTestDist = meanTestDist.rename(columns={'orig_destination_distance':'mean_distance'})\n",
    "dfTest = dfTest.merge(right=meanTestDist,how=\"left\",on=\"srch_id\",validate=\"many_to_one\")\n",
    "diff_distance_orig_Test = (dfTest['orig_destination_distance'] - dfTest['mean_distance'])/dfTest['mean_distance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTrainDist = dfTrain[['srch_id','orig_destination_distance']].groupby(['srch_id']).mean()\n",
    "meanTrainDist = meanTrainDist.rename(columns={'orig_destination_distance':'mean_distance'})\n",
    "dfTrain = dfTrain.merge(right=meanTrainDist,how=\"left\",on=\"srch_id\",validate=\"many_to_one\")\n",
    "diff_distance_orig_Train = (dfTrain['orig_destination_distance'] - dfTrain['mean_distance'])/dfTrain['mean_distance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToAvgPerPropID = ['prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "           'prop_location_score1', 'prop_location_score2',\n",
    "           'prop_log_historical_price']\n",
    "groupedMean = together.groupby('prop_id')[columnsToAvgPerPropID].mean()\n",
    "groupedMean = groupedMean.add_prefix(\"mean_\").reset_index()\n",
    "groupedMean.to_csv(\"meansTotal.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedPropDest = dfTrain.groupby(['srch_destination_id','prop_id']).mean().reset_index()\n",
    "groupedPropDest = groupedPropDest.rename(columns = {\"booking_bool\": \"booking_prop_dest_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedPropTotal = dfTrain.groupby(['prop_id']).mean().reset_index()\n",
    "groupedPropTotal = groupedPropTotal.rename(columns = {\"booking_bool\": \"booking_prop_total_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinPropDest(df):\n",
    "    df = df.merge(right=groupedPropDest[['srch_destination_id','prop_id','booking_prop_dest_mean']],how=\"left\",on=['srch_destination_id','prop_id'],validate=\"many_to_one\")\n",
    "    return df\n",
    "def joinPropDestTotal(df):\n",
    "    df = df.merge(right=groupedPropTotal[['prop_id','booking_prop_total_mean']],how=\"left\",on=['prop_id'],validate=\"many_to_one\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinDistanceTest(df):\n",
    "    df['diff_distance_orig']=diff_distance_orig_Test\n",
    "    return df\n",
    "def joinDistanceTrain(df):\n",
    "    df['diff_distance_orig']=diff_distance_orig_Train\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinMean(df):\n",
    "    df = df.merge(right=meanDF,how=\"left\",on=\"prop_id\",validate=\"many_to_one\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanDF= pd.read_csv(\"meansTotal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler()\n",
    "data = meanDF.drop(['prop_id','mean_prop_review_score','mean_prop_location_score2'],axis=1)\n",
    "mms.fit(data)\n",
    "data_transformed = mms.transform(data)\n",
    "km = KMeans(n_clusters=6)\n",
    "km = km.fit(data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummiesCluster = pd.get_dummies(km.labels_,prefix = \"cluster_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanDF = pd.concat([meanDF,dummiesCluster],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joinMean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joinPropDest(df)\n",
    "df = joinPropDestTotal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joinDistanceTest(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_prop_log_historical_price</th>\n",
       "      <th>cluster__0</th>\n",
       "      <th>cluster__1</th>\n",
       "      <th>cluster__2</th>\n",
       "      <th>cluster__3</th>\n",
       "      <th>cluster__4</th>\n",
       "      <th>cluster__5</th>\n",
       "      <th>booking_prop_dest_mean</th>\n",
       "      <th>booking_prop_total_mean</th>\n",
       "      <th>diff_distance_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>3180</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.196765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>5543</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.283044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>14142</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.786120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>22393</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.295411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-02 15:27:40</td>\n",
       "      <td>24</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>24194</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.011241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0        1  2013-02-02 15:27:40       24                          216   \n",
       "1        1  2013-02-02 15:27:40       24                          216   \n",
       "2        1  2013-02-02 15:27:40       24                          216   \n",
       "3        1  2013-02-02 15:27:40       24                          216   \n",
       "4        1  2013-02-02 15:27:40       24                          216   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                      NaN                   NaN              219     3180   \n",
       "1                      NaN                   NaN              219     5543   \n",
       "2                      NaN                   NaN              219    14142   \n",
       "3                      NaN                   NaN              219    22393   \n",
       "4                      NaN                   NaN              219    24194   \n",
       "\n",
       "   prop_starrating  prop_review_score  ...  mean_prop_log_historical_price  \\\n",
       "0                3                4.5  ...                        4.196765   \n",
       "1                3                4.5  ...                        4.283044   \n",
       "2                2                3.5  ...                        3.786120   \n",
       "3                3                4.5  ...                        4.295411   \n",
       "4                3                4.5  ...                        4.011241   \n",
       "\n",
       "   cluster__0  cluster__1  cluster__2  cluster__3  cluster__4  cluster__5  \\\n",
       "0           0           0           0           0           0           1   \n",
       "1           0           0           0           0           0           1   \n",
       "2           1           0           0           0           0           0   \n",
       "3           0           0           0           0           0           1   \n",
       "4           0           0           0           0           0           1   \n",
       "\n",
       "   booking_prop_dest_mean  booking_prop_total_mean  diff_distance_orig  \n",
       "0                0.077778                 0.043011                 NaN  \n",
       "1                0.142857                 0.053279                 NaN  \n",
       "2                0.000000                 0.013423                 NaN  \n",
       "3                0.026316                 0.013793                 NaN  \n",
       "4                0.010870                 0.014634                 NaN  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/testWithMean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df = joinMean(df)\n",
    "df = joinPropDest(df)\n",
    "df = joinPropDestTotal(df)\n",
    "df = joinDistanceTrain(df)\n",
    "df.to_csv('../data/trainWithMean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df,random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "numOfRowsTest = (int(len(df)*(n/100)))\n",
    "X_test = df.tail(numOfRowsTest)\n",
    "df.drop(df.tail(numOfRowsTest).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('../data/20PercentTestWithMean.csv',index=False)\n",
    "df.to_csv('../data/80PercentTrainWithMean.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
