{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/51/c1/198915b13e98b62a98f48309c41012638464651da755d941f4abe384c012/xgboost-0.82-py2.py3-none-win_amd64.whl (7.7MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\janine van wonderen\\appdata\\roaming\\python\\python36\\site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\janine van wonderen\\anaconda3\\lib\\site-packages (from xgboost) (1.14.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/janine van wonderen/Desktop/dmt2/training_set_VU_DM.csv\",delimiter=\",\", \n",
    "                 usecols = ['srch_id', 'site_id', 'visitor_location_country_id','visitor_hist_starrating', \n",
    "                            'visitor_hist_adr_usd', 'prop_country_id','prop_id', 'prop_starrating', \n",
    "                            'prop_review_score', 'prop_brand_bool','prop_location_score1', 'prop_location_score2',\n",
    "                            'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag',\n",
    "                            'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window','srch_adults_count', \n",
    "                            'srch_children_count', 'srch_room_count','srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "                            'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv', 'click_bool', \n",
    "                            'gross_bookings_usd','booking_bool'])\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train it on clicking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOnlyColumns = ['position','click_bool','booking_bool','gross_bookings_usd']\n",
    "Y = df['click_bool']\n",
    "#df.drop(trainOnlyColumns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "numOfRowsTest = (int(len(df)*(n/100)))\n",
    "X_test = df.tail(numOfRowsTest)\n",
    "Y_test = Y[-numOfRowsTest:]\n",
    "df.drop(df.tail(numOfRowsTest).index,inplace=True)\n",
    "y_train = Y[:(len(Y)-numOfRowsTest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgboost.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgboost.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 1\n",
      "AUC Score (Train): 1.000000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'get_fscore'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4a7cce583158>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m  \u001b[0mscale_pos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m  seed=27)\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodelfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-c869d32d8838>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(alg, dtrain, predictors, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AUC Score (Train): %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain_predprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mfeat_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mfeat_imp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Feature Importances'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature Importance Score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'get_fscore'"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = ['position','click_bool','booking_bool','gross_bookings_usd']\n",
    "target = ['click_bool']\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, df, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=5,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_param = xgb1.get_xgb_params()\n",
    "cv_folds = 2\n",
    "early_stopping_rounds= 10\n",
    "xgtrain = xgboost.DMatrix(df[predictors].values, label=df[target].values)\n",
    "cvresult = xgboost.cv(xgb_param, xgtrain, num_boost_round=xgb1.get_params()['n_estimators'], nfold=cv_folds,\n",
    "           metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "xgb1.set_params(n_estimators=cvresult.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the algorithm on the data\n",
    "xgb1.fit(df[predictors], df['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "#Predict training set:\n",
    "dtrain_predictions = xgb1.predict(dtrain[predictors])\n",
    "dtrain_predprob = xgb1.predict_proba(dtrain[predictors])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "xgb_iets = XGBClassifier(learning_rate =0.1, \n",
    "                         n_estimators=140, \n",
    "                         max_depth=5,\n",
    "                         min_child_weight=1, \n",
    "                         gamma=0, \n",
    "                         subsample=0.8, \n",
    "                         colsample_bytree=0.8,\n",
    "                         objective= 'binary:logistic',\n",
    "                         nthread=4, \n",
    "                         scale_pos_weight=1, \n",
    "                         seed=27\n",
    "                        )\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = xgb_iets,\n",
    "                        param_grid = param_test1,\n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5\n",
    "                       )\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data end, start to boost trees\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "b'[15:58:02] C:\\\\Users\\\\Administrator\\\\Desktop\\\\xgboost\\\\src\\\\objective\\\\rank_obj.cc:52: Check failed: gptr.size() != 0 && gptr.back() == info.labels_.Size() group structure not consistent with #rows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-382cad2c73ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'loading data end, start to boost trees'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mplst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# save out model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'paraTest.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1110\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \"\"\"\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: b'[15:58:02] C:\\\\Users\\\\Administrator\\\\Desktop\\\\xgboost\\\\src\\\\objective\\\\rank_obj.cc:52: Check failed: gptr.size() != 0 && gptr.back() == info.labels_.Size() group structure not consistent with #rows'"
     ]
    }
   ],
   "source": [
    "# construct xgboost.DMatrix from numpy array, treat -999.0 as missing value\n",
    "xgmat = xgboost.DMatrix( df, label=y_train)\n",
    "xgmat.set_group(df[\"srch_id\"])\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use logistic regression loss, use raw prediction before logistic transformation\n",
    "# since we only need the rank\n",
    "param['objective'] = 'rank:pairwise'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight'] = sum(y_train==0)/sum(y_train==1)\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['eval_metric'] = 'auc'\n",
    "param['silent'] = 0\n",
    "param['nthread'] = 10\n",
    "\n",
    "# you can directly throw param in, though we want to watch multiple metrics here\n",
    "plst = list(param.items())+[('eval_metric', 'ams@0.15')]\n",
    "\n",
    "watchlist = [ (xgmat,'train') ]\n",
    "# boost 120 trees\n",
    "num_round = 120\n",
    "print ('loading data end, start to boost trees')\n",
    "bst = xgboost.train( plst, xgmat, num_round, watchlist );\n",
    "# save out model\n",
    "bst.save_model('paraTest.model')\n",
    "\n",
    "print ('finish training')\n",
    "\n",
    "# fit model no training data\n",
    "#model = XGBClassifier()\n",
    "#model.fit(xs, ys)\n",
    "# make predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 779229,\n",
       "         0.0: 1440733,\n",
       "         2.0: 74918,\n",
       "         -1.0: 180183,\n",
       "         3.0: 3805,\n",
       "         -2.0: 305})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgmat_test = xgboost.DMatrix( X_test, label=Y_test)\n",
    "y_pred = bst.predict(xgmat_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srch_id', 'site_id', 'visitor_location_country_id',\n",
       "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
       "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
       "       'prop_location_score1', 'prop_location_score2',\n",
       "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
       "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
       "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
       "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
       "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['site_id', 'visitor_location_country_id',\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
    "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
    "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "numOfRowsTest = (int(len(df2)*(n/100)))\n",
    "X_test = df2.tail(numOfRowsTest)\n",
    "Y_test = Y[-numOfRowsTest:]\n",
    "df2.drop(df2.tail(numOfRowsTest).index,inplace=True)\n",
    "y_train = Y[:(len(Y)-numOfRowsTest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-29bb97bc7507>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# construct xgboost.DMatrix from numpy array, treat -999.0 as missing value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxgmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mxgmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'srch_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# setup parameters for xgboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# construct xgboost.DMatrix from numpy array, treat -999.0 as missing value\n",
    "xgmat = xgboost.DMatrix( df2, label=y_train)\n",
    "\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use logistic regression loss, use raw prediction before logistic transformation\n",
    "# since we only need the rank\n",
    "param['objective'] = 'reg:logistic'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight'] = sum(y_train==0)/sum(y_train==1)\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 8\n",
    "param['eval_metric'] = 'auc'\n",
    "param['silent'] = 0\n",
    "param['nthread'] = 10\n",
    "param['tree_method'] = 'hist'\n",
    "\n",
    "# you can directly throw param in, though we want to watch multiple metrics here\n",
    "plst = list(param.items())+[('eval_metric', 'ams@0.15')]\n",
    "\n",
    "watchlist = [ (xgmat,'train') ]\n",
    "# boost 120 trees\n",
    "num_round = 120\n",
    "print ('loading data end, start to boost trees')\n",
    "bst = xgboost.train( plst, xgmat, num_round, watchlist );\n",
    "# save out model\n",
    "bst.save_model('paraTest2.model')\n",
    "\n",
    "print ('finish training')\n",
    "\n",
    "# fit model no training data\n",
    "#model = XGBClassifier()\n",
    "#model.fit(xs, ys)\n",
    "# make predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 791162, 0.0: 1688011})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgmat_test = xgboost.DMatrix( X_test, label=Y_test)\n",
    "y_pred = bst.predict(xgmat_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df[[\"prop_location_score2\", \"srch_query_affinity_score\", \"promotion_flag\",\"prop_starrating\", \n",
    "         \"random_bool\", \"srch_length_of_stay\", \"prop_review_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "numOfRowsTest = (int(len(df3)*(n/100)))\n",
    "X_test = df3.tail(numOfRowsTest)\n",
    "Y_test = Y[-numOfRowsTest:]\n",
    "df3.drop(df3.tail(numOfRowsTest).index,inplace=True)\n",
    "y_train = Y[:(len(Y)-numOfRowsTest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data end, start to boost trees\n",
      "[0]\ttrain-auc:0.641337\ttrain-ams@0.15:50.3717\n",
      "[1]\ttrain-auc:0.642473\ttrain-ams@0.15:50.6822\n",
      "[2]\ttrain-auc:0.642932\ttrain-ams@0.15:50.592\n",
      "[3]\ttrain-auc:0.643611\ttrain-ams@0.15:51.3104\n",
      "[4]\ttrain-auc:0.643857\ttrain-ams@0.15:51.4545\n",
      "[5]\ttrain-auc:0.644436\ttrain-ams@0.15:51.6317\n",
      "[6]\ttrain-auc:0.644883\ttrain-ams@0.15:52.2884\n",
      "[7]\ttrain-auc:0.645283\ttrain-ams@0.15:52.3058\n",
      "[8]\ttrain-auc:0.645566\ttrain-ams@0.15:52.4049\n",
      "[9]\ttrain-auc:0.645787\ttrain-ams@0.15:52.4153\n",
      "[10]\ttrain-auc:0.646281\ttrain-ams@0.15:52.4988\n",
      "[11]\ttrain-auc:0.646555\ttrain-ams@0.15:52.5544\n",
      "[12]\ttrain-auc:0.646763\ttrain-ams@0.15:52.6431\n",
      "[13]\ttrain-auc:0.647018\ttrain-ams@0.15:52.6379\n",
      "[14]\ttrain-auc:0.647387\ttrain-ams@0.15:52.7735\n",
      "[15]\ttrain-auc:0.647625\ttrain-ams@0.15:52.8535\n",
      "[16]\ttrain-auc:0.647765\ttrain-ams@0.15:52.8709\n",
      "[17]\ttrain-auc:0.647993\ttrain-ams@0.15:52.9596\n",
      "[18]\ttrain-auc:0.648217\ttrain-ams@0.15:53.0883\n",
      "[19]\ttrain-auc:0.648377\ttrain-ams@0.15:53.0605\n",
      "[20]\ttrain-auc:0.64852\ttrain-ams@0.15:53.0779\n",
      "[21]\ttrain-auc:0.648698\ttrain-ams@0.15:53.1022\n",
      "[22]\ttrain-auc:0.648921\ttrain-ams@0.15:53.0727\n",
      "[23]\ttrain-auc:0.649058\ttrain-ams@0.15:53.1353\n",
      "[24]\ttrain-auc:0.649241\ttrain-ams@0.15:53.1388\n",
      "[25]\ttrain-auc:0.649397\ttrain-ams@0.15:53.1631\n",
      "[26]\ttrain-auc:0.64962\ttrain-ams@0.15:53.2205\n",
      "[27]\ttrain-auc:0.649777\ttrain-ams@0.15:53.2362\n",
      "[28]\ttrain-auc:0.649914\ttrain-ams@0.15:53.2797\n",
      "[29]\ttrain-auc:0.650078\ttrain-ams@0.15:53.3197\n",
      "[30]\ttrain-auc:0.650243\ttrain-ams@0.15:53.3197\n",
      "[31]\ttrain-auc:0.65041\ttrain-ams@0.15:53.3928\n",
      "[32]\ttrain-auc:0.650529\ttrain-ams@0.15:53.3824\n",
      "[33]\ttrain-auc:0.650658\ttrain-ams@0.15:53.4589\n",
      "[34]\ttrain-auc:0.65075\ttrain-ams@0.15:53.499\n",
      "[35]\ttrain-auc:0.650922\ttrain-ams@0.15:53.5599\n",
      "[36]\ttrain-auc:0.651073\ttrain-ams@0.15:53.6243\n",
      "[37]\ttrain-auc:0.651272\ttrain-ams@0.15:53.7618\n",
      "[38]\ttrain-auc:0.651392\ttrain-ams@0.15:53.8141\n",
      "[39]\ttrain-auc:0.651484\ttrain-ams@0.15:53.8141\n",
      "[40]\ttrain-auc:0.651557\ttrain-ams@0.15:53.8506\n",
      "[41]\ttrain-auc:0.651684\ttrain-ams@0.15:53.8733\n",
      "[42]\ttrain-auc:0.65178\ttrain-ams@0.15:53.9359\n",
      "[43]\ttrain-auc:0.651833\ttrain-ams@0.15:53.9603\n",
      "[44]\ttrain-auc:0.652001\ttrain-ams@0.15:54.0108\n",
      "[45]\ttrain-auc:0.652072\ttrain-ams@0.15:54.0108\n",
      "[46]\ttrain-auc:0.652085\ttrain-ams@0.15:54.0265\n",
      "[47]\ttrain-auc:0.65222\ttrain-ams@0.15:54.0265\n",
      "[48]\ttrain-auc:0.652237\ttrain-ams@0.15:54.0056\n",
      "[49]\ttrain-auc:0.652335\ttrain-ams@0.15:54.07\n",
      "[50]\ttrain-auc:0.652423\ttrain-ams@0.15:54.0927\n",
      "[51]\ttrain-auc:0.652446\ttrain-ams@0.15:54.0979\n",
      "[52]\ttrain-auc:0.652576\ttrain-ams@0.15:54.1397\n",
      "[53]\ttrain-auc:0.652629\ttrain-ams@0.15:54.1623\n",
      "[54]\ttrain-auc:0.652698\ttrain-ams@0.15:54.1989\n",
      "[55]\ttrain-auc:0.652772\ttrain-ams@0.15:54.2233\n",
      "[56]\ttrain-auc:0.652814\ttrain-ams@0.15:54.2268\n",
      "[57]\ttrain-auc:0.652855\ttrain-ams@0.15:54.3505\n",
      "[58]\ttrain-auc:0.652894\ttrain-ams@0.15:54.3592\n",
      "[59]\ttrain-auc:0.652974\ttrain-ams@0.15:54.394\n",
      "[60]\ttrain-auc:0.652998\ttrain-ams@0.15:54.408\n",
      "[61]\ttrain-auc:0.653076\ttrain-ams@0.15:54.4254\n",
      "[62]\ttrain-auc:0.653157\ttrain-ams@0.15:54.4655\n",
      "[63]\ttrain-auc:0.653198\ttrain-ams@0.15:54.4777\n",
      "[64]\ttrain-auc:0.65325\ttrain-ams@0.15:54.4777\n",
      "[65]\ttrain-auc:0.653357\ttrain-ams@0.15:54.4899\n",
      "[66]\ttrain-auc:0.653448\ttrain-ams@0.15:54.4864\n",
      "[67]\ttrain-auc:0.653474\ttrain-ams@0.15:54.4951\n",
      "[68]\ttrain-auc:0.653526\ttrain-ams@0.15:54.5073\n",
      "[69]\ttrain-auc:0.653583\ttrain-ams@0.15:54.5265\n",
      "[70]\ttrain-auc:0.653636\ttrain-ams@0.15:54.5456\n",
      "[71]\ttrain-auc:0.653645\ttrain-ams@0.15:54.5421\n",
      "[72]\ttrain-auc:0.653726\ttrain-ams@0.15:54.6258\n",
      "[73]\ttrain-auc:0.653818\ttrain-ams@0.15:54.6484\n",
      "[74]\ttrain-auc:0.653944\ttrain-ams@0.15:54.6868\n",
      "[75]\ttrain-auc:0.653998\ttrain-ams@0.15:54.7094\n",
      "[76]\ttrain-auc:0.654026\ttrain-ams@0.15:54.7094\n",
      "[77]\ttrain-auc:0.654107\ttrain-ams@0.15:54.7373\n",
      "[78]\ttrain-auc:0.654249\ttrain-ams@0.15:54.7495\n",
      "[79]\ttrain-auc:0.65431\ttrain-ams@0.15:54.7704\n",
      "[80]\ttrain-auc:0.654361\ttrain-ams@0.15:54.7826\n",
      "[81]\ttrain-auc:0.654452\ttrain-ams@0.15:54.8088\n",
      "[82]\ttrain-auc:0.654498\ttrain-ams@0.15:54.8105\n",
      "[83]\ttrain-auc:0.654546\ttrain-ams@0.15:54.8175\n",
      "[84]\ttrain-auc:0.654588\ttrain-ams@0.15:54.8227\n",
      "[85]\ttrain-auc:0.654597\ttrain-ams@0.15:54.8227\n",
      "[86]\ttrain-auc:0.654618\ttrain-ams@0.15:54.8262\n",
      "[87]\ttrain-auc:0.654675\ttrain-ams@0.15:54.8506\n",
      "[88]\ttrain-auc:0.654691\ttrain-ams@0.15:54.8646\n",
      "[89]\ttrain-auc:0.65473\ttrain-ams@0.15:54.8663\n",
      "[90]\ttrain-auc:0.65483\ttrain-ams@0.15:54.889\n",
      "[91]\ttrain-auc:0.65496\ttrain-ams@0.15:54.889\n",
      "[92]\ttrain-auc:0.655067\ttrain-ams@0.15:54.9291\n",
      "[93]\ttrain-auc:0.655291\ttrain-ams@0.15:55.0563\n",
      "[94]\ttrain-auc:0.655356\ttrain-ams@0.15:55.086\n",
      "[95]\ttrain-auc:0.655406\ttrain-ams@0.15:55.0982\n",
      "[96]\ttrain-auc:0.655428\ttrain-ams@0.15:55.1052\n",
      "[97]\ttrain-auc:0.655466\ttrain-ams@0.15:55.1156\n",
      "[98]\ttrain-auc:0.655592\ttrain-ams@0.15:55.1889\n",
      "[99]\ttrain-auc:0.655616\ttrain-ams@0.15:55.1889\n",
      "[100]\ttrain-auc:0.655623\ttrain-ams@0.15:55.1941\n",
      "[101]\ttrain-auc:0.655792\ttrain-ams@0.15:55.2377\n",
      "[102]\ttrain-auc:0.655892\ttrain-ams@0.15:55.2482\n",
      "[103]\ttrain-auc:0.655924\ttrain-ams@0.15:55.2551\n",
      "[104]\ttrain-auc:0.655995\ttrain-ams@0.15:55.2761\n",
      "[105]\ttrain-auc:0.65614\ttrain-ams@0.15:55.3685\n",
      "[106]\ttrain-auc:0.656174\ttrain-ams@0.15:55.3842\n",
      "[107]\ttrain-auc:0.656212\ttrain-ams@0.15:55.3894\n",
      "[108]\ttrain-auc:0.656291\ttrain-ams@0.15:55.4138\n",
      "[109]\ttrain-auc:0.656326\ttrain-ams@0.15:55.4103\n",
      "[110]\ttrain-auc:0.656422\ttrain-ams@0.15:55.4156\n",
      "[111]\ttrain-auc:0.65648\ttrain-ams@0.15:55.4295\n",
      "[112]\ttrain-auc:0.656536\ttrain-ams@0.15:55.4383\n",
      "[113]\ttrain-auc:0.656564\ttrain-ams@0.15:55.4801\n",
      "[114]\ttrain-auc:0.656624\ttrain-ams@0.15:55.4958\n",
      "[115]\ttrain-auc:0.656641\ttrain-ams@0.15:55.4976\n",
      "[116]\ttrain-auc:0.656668\ttrain-ams@0.15:55.5028\n",
      "[117]\ttrain-auc:0.656788\ttrain-ams@0.15:55.5743\n",
      "[118]\ttrain-auc:0.656847\ttrain-ams@0.15:55.5813\n",
      "[119]\ttrain-auc:0.656853\ttrain-ams@0.15:55.5796\n",
      "finish training\n"
     ]
    }
   ],
   "source": [
    "# construct xgboost.DMatrix from numpy array, treat -999.0 as missing value\n",
    "xgmat = xgboost.DMatrix( df3, label=y_train)\n",
    "\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use logistic regression loss, use raw prediction before logistic transformation\n",
    "# since we only need the rank\n",
    "param['objective'] = 'reg:logistic'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight'] = sum(y_train==0)/sum(y_train==1)\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['eval_metric'] = 'auc'\n",
    "param['silent'] = 0\n",
    "param['nthread'] = 10\n",
    "\n",
    "# you can directly throw param in, though we want to watch multiple metrics here\n",
    "plst = list(param.items())+[('eval_metric', 'ams@0.15')]\n",
    "\n",
    "watchlist = [ (xgmat,'train') ]\n",
    "# boost 120 trees\n",
    "num_round = 120\n",
    "print ('loading data end, start to boost trees')\n",
    "bst = xgboost.train( plst, xgmat, num_round, watchlist );\n",
    "# save out model\n",
    "bst.save_model('paraTest.model')\n",
    "\n",
    "print ('finish training')\n",
    "\n",
    "# fit model no training data\n",
    "#model = XGBClassifier()\n",
    "#model.fit(xs, ys)\n",
    "# make predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\janine van wonderen\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.30%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 1092187, 0.0: 1386986})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgmat_test = xgboost.DMatrix( X_test, label=Y_test)\n",
    "y_pred = bst.predict(xgmat_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train it on booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOnlyColumns = ['position','click_bool','booking_bool','gross_bookings_usd']\n",
    "Y = df['booking_bool']\n",
    "df.drop(trainOnlyColumns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "numOfRowsTest = (int(len(df)*(n/100)))\n",
    "X_test = df.tail(numOfRowsTest)\n",
    "Y_test = Y[-numOfRowsTest:]\n",
    "df.drop(df.tail(numOfRowsTest).index,inplace=True)\n",
    "y_train = Y[:(len(Y)-numOfRowsTest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct xgboost.DMatrix from numpy array, treat -999.0 as missing value\n",
    "xgmat = xgboost.DMatrix( df, label=y_train)\n",
    "\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use logistic regression loss, use raw prediction before logistic transformation\n",
    "# since we only need the rank\n",
    "param['objective'] = 'reg:logistic'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight'] = sum(y_train==0)/sum(y_train==1)\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['eval_metric'] = 'auc'\n",
    "param['silent'] = 0\n",
    "param['nthread'] = 10\n",
    "\n",
    "# you can directly throw param in, though we want to watch multiple metrics here\n",
    "plst = list(param.items())+[('eval_metric', 'ams@0.15')]\n",
    "\n",
    "watchlist = [ (xgmat,'train') ]\n",
    "# boost 120 trees\n",
    "num_round = 25\n",
    "print ('loading data end, start to boost trees')\n",
    "bst = xgboost.train( plst, xgmat, num_round, watchlist , early_stopping_rounds=10);\n",
    "# save out model\n",
    "bst.save_model('bookingModel.model')\n",
    "\n",
    "print ('finish training')\n",
    "\n",
    "# fit model no training data\n",
    "#model = XGBClassifier()\n",
    "#model.fit(xs, ys)\n",
    "# make predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgmat_test = xgboost.DMatrix( X_test, label=Y_test)\n",
    "y_pred = bst.predict(xgmat_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgboost.Booster({'nthread': 12})  # init model\n",
    "bst.load_model('xgboostBinary26April.model')  # load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('../data/test.csv', delimiter=\",\", usecols = ['srch_id', 'site_id', 'visitor_location_country_id',\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
    "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price',  'price_usd', 'promotion_flag',\n",
    "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv'])\n",
    "xgmat_test_submission = xgboost.DMatrix( dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clicking = bst.predict(xgmat_test_submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgboost.Booster({'nthread': 12})  # init model\n",
    "bst.load_model('bookingModel.model')  # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_booking = bst.predict(xgmat_test_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_clicking + y_pred_booking\n",
    "dfTest['predictedPos'] = y_pred\n",
    "dfTest = dfTest.sort_values(['srch_id','predictedPos'],ascending=[True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTest.head())\n",
    "dfSubmission = dfTest[['srch_id','prop_id']]\n",
    "dfSubmission.to_csv(\"submissionTest2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(y_pred)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "Counter(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
