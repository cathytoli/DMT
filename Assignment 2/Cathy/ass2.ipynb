{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iMPORT PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4958347"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/cathytol/Documents/DMT/dmt-data/'\n",
    "\n",
    "inputFile = path + \"training_set_VU_DM.csv\"\n",
    "df = pd.read_csv(inputFile, sep = ',')\n",
    "#df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "df = shuffle(df[['srch_id', 'site_id', 'visitor_location_country_id',\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
    "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag',\n",
    "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv', 'click_bool', 'gross_bookings_usd',\n",
    "       'booking_bool']])\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "trainOnlyColumns = ['position','click_bool','booking_bool','gross_bookings_usd']\n",
    "X = df.drop(trainOnlyColumns, axis=1)\n",
    "Y_click = df['click_bool']\n",
    "Y_book = df['booking_bool']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"% clicks: \", sum(df['click_bool'])/4958347*100)\n",
    "print(\"% bookings: \", sum(df['booking_bool'])/4958347*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = path + \"test_set_VU_DM.csv\"\n",
    "df_evaluate = pd.read_csv(inputFile, sep = ',')\n",
    "df_evaluate = df_evaluate[['srch_id', 'site_id', 'visitor_location_country_id',\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
    "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
    "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(df, y_click, y_book):\n",
    "    df['gain'] = df[y_click]+5*df[y_book]\n",
    "    df['ind'] = df.index+1\n",
    "\n",
    "    df['g/i'] = df['gain']/df['ind']\n",
    "    gi_sum = df['g/i'].sum()\n",
    "\n",
    "    df['gain_sorted'] = list(df['gain'].sort_values(ascending = False))\n",
    "    df['g/i_sorted'] = df['gain_sorted']/df['ind']\n",
    "    gi_sorted_sum = df['g/i_sorted'].sum()\n",
    "    \n",
    "    score = gi_sum/gi_sorted_sum\n",
    "\n",
    "    return score, gi_sum, gi_sorted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xg boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use logistic regression loss, use raw prediction before logistic transformation\n",
    "# since we only need the rank\n",
    "param['objective'] = 'reg:logistic'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight'] = sum(y_train==0)/sum(y_train==1)\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['eval_metric'] = 'auc'\n",
    "param['silent'] = 0\n",
    "param['nthread'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7834314792567336\n",
      "0.3202264084221033\n",
      "0.4087484571412835\n"
     ]
    }
   ],
   "source": [
    "# first predict click\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_click, test_size=0.2, random_state=123)\n",
    "xg_reg_click = xgb.XGBRegressor(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 50)\n",
    "\n",
    "xg_reg_click.fit(X_train,y_train)\n",
    "preds_click = xg_reg_click.predict(X_test)\n",
    "\n",
    "X_fin = X_test\n",
    "X_fin['preds_click'] = preds_click\n",
    "X_fin['y_click'] = y_test\n",
    "\n",
    "# ten predict book\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_book, test_size=0.2, random_state=123)\n",
    "xg_reg_book = xgb.XGBRegressor(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 50)\n",
    "\n",
    "xg_reg_book.fit(X_train,y_train)\n",
    "preds_book = xg_reg_book.predict(X_test)\n",
    "\n",
    "\n",
    "X_fin['preds_book'] = preds_book\n",
    "X_fin['y_book'] = y_test\n",
    "\n",
    "\n",
    "score, gi_sum, gi_sorted_sum = getScore(X_fin.sort_values(by=['preds_book', 'preds_click'], ascending = False), 'y_click', 'y_book')\n",
    "print(score)\n",
    "print(gi_sum)\n",
    "print(gi_sorted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7732298447524493\n",
      "0.3202264084221037\n",
      "0.4141412939442666\n"
     ]
    }
   ],
   "source": [
    "score, gi_sum, gi_sorted_sum = getScore(X_fin.sort_values(by=['srch_id', 'preds_book', 'preds_click'], ascending = [True, False, False]), 'y_click', 'y_book')\n",
    "print(score)\n",
    "print(gi_sum)\n",
    "print(gi_sorted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_click_eval = xg_reg_click.predict(df_evaluate)\n",
    "preds_book_eval = xg_reg_book.predict(df_evaluate)\n",
    "\n",
    "df_evaluate['preds_click'] = preds_click_eval\n",
    "df_evaluate['preds_book'] = preds_book_eval\n",
    "\n",
    "df_evaluate = df_evaluate.sort_values(['srch_id','preds_book', 'preds_click'],ascending=[True, False, False])\n",
    "\n",
    "dfSubmission = df_evaluate[['srch_id','prop_id']]\n",
    "dfSubmission.to_csv(\"submission_cathy_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix_click = xgb.DMatrix(data=X,label=Y_click)\n",
    "data_dmatrix_book = xgb.DMatrix(data=X,label=Y_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix_book, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.datacamp.com/community/tutorials/xgboost-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOG NIET GEBRUIKT\n",
    "\n",
    "## NORMALISE dict\n",
    "def normaliseDF(df):\n",
    "    maxDict = {}\n",
    "    minDict = {}\n",
    "    for column in df.columns:\n",
    "        maxi = df[column].max()\n",
    "        maxDict[column] = maxi\n",
    "        mini = df[column].min()\n",
    "        minDict[column] = mini\n",
    "        if (column != \"id\") and (column != \"date\") and (column != \"mood_mean_TARGET\"):\n",
    "            df[column] = ((df[column]-mini)/(maxi-mini))\n",
    "    return df, maxDict, minDict\n",
    "\n",
    "df, maxDict, minDict = normaliseDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REVERSE - NORMALISE \n",
    "def reverseNormaliseDF(df, maxDict, minDict):\n",
    "    for column in df.columns:\n",
    "        maxi = maxDict[column]\n",
    "        mini = minDict[column]\n",
    "        if (column != \"id\") and (column != \"date\") and (column != \"mood_mean\"):\n",
    "            df[column] = (df[column]*(maxi-mini)) + mini\n",
    "    return df\n",
    "\n",
    "#df = reverseNormaliseDF(df, maxDict, minDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"out_with_nan_mood_normalised.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(subset = ['mood_mean'] ).to_csv(\"out_without_nan_mood_normalised.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(subset = ['mood_mean_TARGET'] ).to_csv(\"out_without_nan_mood_target_normalised.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SHOW CORRELATIONS\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr[['click_bool', 'booking_bool', 'gain']].style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['date_time', 'click_bool', 'booking_bool', 'gain', 'ind', 'g/i', 'gain_sorted', 'g/i_sorted'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['visitor_location_country_id', 'prop_country_id', 'prop_starrating', 'prop_brand_bool', 'prop_location_score1', \n",
    "  'prop_log_historical_price', 'price_usd', 'promotion_flag', 'srch_destination_id', 'srch_length_of_stay',\n",
    "   'srch_booking_window', 'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool',\n",
    "   'random_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['click_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputFile = path + \"test_set_VU_DM.csv\"\n",
    "df_test = pd.read_csv(inputFile, sep = ',')\n",
    "#df_test['date_time'] = pd.to_datetime(df_test['date_time'])\n",
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[['visitor_location_country_id', 'prop_country_id', 'prop_starrating', 'prop_brand_bool', 'prop_location_score1', \n",
    "  'prop_log_historical_price', 'price_usd', 'promotion_flag', 'srch_destination_id', 'srch_length_of_stay',\n",
    "   'srch_booking_window', 'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool',\n",
    "   'random_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
