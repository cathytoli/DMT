{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iMPORT PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x1a7a1e0240>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cathytol/anaconda3/lib/python3.6/site-packages/xgboost/core.py\", line 482, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3966678\n",
      "991669\n",
      "4959183\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/cathytol/Documents/DMT/dmt-data/'\n",
    "trainOnlyColumns = ['position','click_bool','booking_bool','gross_bookings_usd']\n",
    "\n",
    "colsToUse = ['srch_id', 'site_id', 'visitor_location_country_id',\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
    "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
    "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance_x', 'random_bool', 'comp1_rate', 'comp1_inv',\n",
    "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
    "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
    "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
    "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
    "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
    "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
    "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
    "       'comp8_rate_percent_diff', 'mean_prop_starrating', 'mean_prop_review_score',\n",
    "       'mean_prop_brand_bool', 'mean_prop_location_score1',\n",
    "       'mean_prop_location_score2', 'mean_prop_log_historical_price',\n",
    "       'cluster__0', 'cluster__1', 'cluster__2', 'cluster__3', 'cluster__4',\n",
    "       'cluster__5', 'bookingSum', 'orig_destination_distance_y']\n",
    "\n",
    "inputFile = path + \"80PercentTrainWithMean.csv\"\n",
    "dfTrain = pd.read_csv(inputFile, sep = ',')\n",
    "print(len(dfTrain))\n",
    "\n",
    "#X_train = dfTrain.drop(trainOnlyColumns, axis=1)\n",
    "X_train = dfTrain[colsToUse]\n",
    "Y_click_train = dfTrain['click_bool']\n",
    "Y_book_train = dfTrain['booking_bool']\n",
    "\n",
    "inputFile = path + \"20PercentTestWithMean.csv\"\n",
    "dfTest = pd.read_csv(inputFile, sep = ',')\n",
    "print(len(dfTest))\n",
    "\n",
    "#X_test = dfTest.drop(trainOnlyColumns, axis=1)\n",
    "X_test = dfTest[colsToUse]\n",
    "Y_click_test = dfTest['click_bool']\n",
    "Y_book_test = dfTest['booking_bool']\n",
    "\n",
    "\n",
    "inputFile = path + \"testWithMean.csv\"\n",
    "dfEval = pd.read_csv(inputFile, sep = ',')\n",
    "print(len(dfEval))\n",
    "\n",
    "X_eval = dfEval[colsToUse]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srch_id', 'site_id', 'visitor_location_country_id',\n",
       "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
       "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
       "       'prop_location_score1', 'prop_location_score2',\n",
       "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
       "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
       "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
       "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
       "       'orig_destination_distance_x', 'random_bool', 'comp1_rate', 'comp1_inv',\n",
       "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
       "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
       "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
       "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
       "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
       "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
       "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
       "       'comp8_rate_percent_diff', 'mean_prop_starrating',\n",
       "       'mean_prop_review_score', 'mean_prop_brand_bool',\n",
       "       'mean_prop_location_score1', 'mean_prop_location_score2',\n",
       "       'mean_prop_log_historical_price', 'cluster__0', 'cluster__1',\n",
       "       'cluster__2', 'cluster__3', 'cluster__4', 'cluster__5', 'bookingSum',\n",
       "       'orig_destination_distance_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "path = '/Users/cathytol/Documents/DMT/dmt-data/'\n",
    "\n",
    "inputFile = path + \"training_set_VU_DM.csv\"\n",
    "df = pd.read_csv(inputFile, sep = ',')\n",
    "#df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "df = shuffle(df[['srch_id', 'site_id', 'visitor_location_country_id',\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
    "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag',\n",
    "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv', 'click_bool', 'gross_bookings_usd',\n",
    "       'booking_bool']])\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "trainOnlyColumns = ['position','click_bool','booking_bool','gross_bookings_usd']\n",
    "X = df.drop(trainOnlyColumns, axis=1)\n",
    "Y_click = df['click_bool']\n",
    "Y_book = df['booking_bool']\n",
    "len(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "print(\"% clicks: \", sum(df['click_bool'])/4958347*100)\n",
    "print(\"% bookings: \", sum(df['booking_bool'])/4958347*100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "inputFile = path + \"test_set_VU_DM.csv\"\n",
    "df_evaluate = pd.read_csv(inputFile, sep = ',')\n",
    "df_evaluate = df_evaluate[['srch_id', 'site_id', 'visitor_location_country_id',\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
    "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
    "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv']]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xg boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first predict click\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y_click, test_size=0.2, random_state=123)\n",
    "\n",
    "xg_reg_click = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 6, alpha = 10,  n_estimators = 2, scale_pos_weight = sum(Y_click_train==0)/sum(Y_click_train==1))\n",
    "\n",
    "xg_reg_click.fit(X_train, Y_click_train, verbose = True)\n",
    "preds_click = xg_reg_click.predict(X_test)\n",
    "\n",
    "X_fin = X_test.copy()\n",
    "X_fin['pred_click_bool'] = preds_click\n",
    "X_fin['click_bool'] = Y_click_test\n",
    "\n",
    "# then predict book\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y_book, test_size=0.2, random_state=123)\n",
    "\n",
    "xg_reg_book = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 2, scale_pos_weight = sum(Y_book_train==0)/sum(Y_book_train==1))\n",
    "\n",
    "xg_reg_book.fit(X_train, Y_book_train, verbose = True)\n",
    "preds_book = xg_reg_book.predict(X_test)\n",
    "\n",
    "X_fin['pred_booking_bool'] = preds_book\n",
    "X_fin['booking_bool'] = Y_book_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(df):\n",
    "    df['rank_srch_id'] = df.groupby('srch_id').cumcount().add(1)\n",
    "    \n",
    "    df['gain'] = 5*df['booking_bool']\n",
    "    df['gain'] = np.where(df['gain'] == 0, df['click_bool'], df['gain'])\n",
    "    \n",
    "    \n",
    "\n",
    "    df['g/rank'] = df['gain']/df['rank_srch_id']\n",
    "    gi_sum = df['g/rank'].sum()\n",
    "\n",
    "    df['gain_sorted'] = list(df[['srch_id', 'booking_bool', 'click_bool', 'gain']].sort_values(by = ['srch_id','booking_bool','click_bool'], ascending = [True, False, False])['gain'])\n",
    "    df['g/rank_sorted'] = df['gain_sorted']/df['rank_srch_id']\n",
    "    gi_sorted_sum = df['g/rank_sorted'].sum()\n",
    "    \n",
    "    score = gi_sum/gi_sorted_sum\n",
    "\n",
    "    return score, gi_sum, gi_sorted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6033377608343748\n",
      "93867.45546675549\n",
      "155580.27619047617\n"
     ]
    }
   ],
   "source": [
    "score, gi_sum, gi_sorted_sum = getScore(X_fin.sort_values(by=['srch_id', 'pred_booking_bool', 'pred_click_bool'], ascending = [True, False, False]).reset_index(drop=True))\n",
    "print(score)\n",
    "print(gi_sum)\n",
    "print(gi_sorted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6033412041647174"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_click_eval = xg_reg_click.predict(dfEval)\n",
    "preds_book_eval = xg_reg_book.predict(dfEval)\n",
    "\n",
    "dfEval['pred_click_bool'] = preds_click_eval\n",
    "dfEval['pred_booking_bool'] = preds_book_eval\n",
    "\n",
    "dfEval = dfEval.sort_values(['srch_id','pred_booking_bool', 'pred_click_bool'],ascending=[True, False, False])\n",
    "\n",
    "dfSubmission = dfEval[['srch_id','prop_id']]\n",
    "dfSubmission.to_csv(\"submission_cathy_3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_click_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# niks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordt niet gebruikt \n",
    "\"\"\" \n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use logistic regression loss, use raw prediction before logistic transformation\n",
    "# since we only need the rank\n",
    "param['objective'] = 'reg:logistic'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight'] = sum(y_train==0)/sum(y_train==1)\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['eval_metric'] = 'auc'\n",
    "param['silent'] = 0\n",
    "param['nthread'] = 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix_click = xgb.DMatrix(data=X,label=Y_click)\n",
    "data_dmatrix_book = xgb.DMatrix(data=X,label=Y_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix_book, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.datacamp.com/community/tutorials/xgboost-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOG NIET GEBRUIKT\n",
    "\n",
    "## NORMALISE dict\n",
    "def normaliseDF(df):\n",
    "    maxDict = {}\n",
    "    minDict = {}\n",
    "    for column in df.columns:\n",
    "        maxi = df[column].max()\n",
    "        maxDict[column] = maxi\n",
    "        mini = df[column].min()\n",
    "        minDict[column] = mini\n",
    "        if (column != \"id\") and (column != \"date\") and (column != \"mood_mean_TARGET\"):\n",
    "            df[column] = ((df[column]-mini)/(maxi-mini))\n",
    "    return df, maxDict, minDict\n",
    "\n",
    "df, maxDict, minDict = normaliseDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REVERSE - NORMALISE \n",
    "def reverseNormaliseDF(df, maxDict, minDict):\n",
    "    for column in df.columns:\n",
    "        maxi = maxDict[column]\n",
    "        mini = minDict[column]\n",
    "        if (column != \"id\") and (column != \"date\") and (column != \"mood_mean\"):\n",
    "            df[column] = (df[column]*(maxi-mini)) + mini\n",
    "    return df\n",
    "\n",
    "#df = reverseNormaliseDF(df, maxDict, minDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"out_with_nan_mood_normalised.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(subset = ['mood_mean'] ).to_csv(\"out_without_nan_mood_normalised.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(subset = ['mood_mean_TARGET'] ).to_csv(\"out_without_nan_mood_target_normalised.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SHOW CORRELATIONS\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr[['click_bool', 'booking_bool', 'gain']].style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['date_time', 'click_bool', 'booking_bool', 'gain', 'ind', 'g/i', 'gain_sorted', 'g/i_sorted'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['visitor_location_country_id', 'prop_country_id', 'prop_starrating', 'prop_brand_bool', 'prop_location_score1', \n",
    "  'prop_log_historical_price', 'price_usd', 'promotion_flag', 'srch_destination_id', 'srch_length_of_stay',\n",
    "   'srch_booking_window', 'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool',\n",
    "   'random_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['click_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputFile = path + \"test_set_VU_DM.csv\"\n",
    "df_test = pd.read_csv(inputFile, sep = ',')\n",
    "#df_test['date_time'] = pd.to_datetime(df_test['date_time'])\n",
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[['visitor_location_country_id', 'prop_country_id', 'prop_starrating', 'prop_brand_bool', 'prop_location_score1', \n",
    "  'prop_log_historical_price', 'price_usd', 'promotion_flag', 'srch_destination_id', 'srch_length_of_stay',\n",
    "   'srch_booking_window', 'srch_adults_count', 'srch_children_count', 'srch_room_count', 'srch_saturday_night_bool',\n",
    "   'random_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/@nikhilbd/intuitive-explanation-of-learning-to-rank-and-ranknet-lambdarank-and-lambdamart-fe1e17fac418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/ogrisel/notebooks/blob/master/Learning%20to%20Rank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/xgboost-python-mini-course/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
