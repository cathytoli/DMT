{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# iMPORT PACKAGES\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from time import time\n",
    "\n",
    "# for multivariate data preparation\n",
    "from numpy import array\n",
    "from numpy import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FILE\n",
    "path = '/Users/cathytol/Documents/DMT/DMT/'\n",
    "inputPath = path + \"out_without_nan_mood_target_normalised.csv\"\n",
    "df = pd.read_csv(inputPath)\n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['mood_mean','mood_mean_TARGET'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train set\n",
    "length_test = round(len(df)*0.33)\n",
    "index_test = np.random.choice(np.arange(len(df)), length_test, False)\n",
    "\n",
    "test = df.iloc[index_test]\n",
    "train = df.drop(df.index[index_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv(\"test_set\", index = False)\n",
    "#train.to_csv(\"train_set\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_set.csv\")\n",
    "train = pd.read_csv(\"train_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_mean</th>\n",
       "      <th>circumplex.arousal_mean</th>\n",
       "      <th>circumplex.valence_mean</th>\n",
       "      <th>mood_mean</th>\n",
       "      <th>appCat.builtin_sum</th>\n",
       "      <th>appCat.communication_sum</th>\n",
       "      <th>appCat.entertainment_sum</th>\n",
       "      <th>appCat.finance_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>appCat.travel_sum_time_5</th>\n",
       "      <th>appCat.unknown_sum_time_5</th>\n",
       "      <th>appCat.utilities_sum_time_5</th>\n",
       "      <th>appCat.weather_sum_time_5</th>\n",
       "      <th>call_sum_time_5</th>\n",
       "      <th>screen_sum_time_5</th>\n",
       "      <th>sms_sum_time_5</th>\n",
       "      <th>day_time_5</th>\n",
       "      <th>weekDay_time_5</th>\n",
       "      <th>mood_mean_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.052727</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>0.236766</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>0.077850</td>\n",
       "      <td>0.303150</td>\n",
       "      <td>0.028033</td>\n",
       "      <td>0.037502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067479</td>\n",
       "      <td>0.012146</td>\n",
       "      <td>0.138491</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.226449</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-22</td>\n",
       "      <td>0.418390</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>0.018139</td>\n",
       "      <td>0.239538</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070228</td>\n",
       "      <td>0.012146</td>\n",
       "      <td>0.164772</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.295118</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.281818</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-25</td>\n",
       "      <td>0.173753</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.025612</td>\n",
       "      <td>0.496012</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.032589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.063247</td>\n",
       "      <td>0.256523</td>\n",
       "      <td>0.05825</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.753727</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-27</td>\n",
       "      <td>0.281736</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>0.334794</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034432</td>\n",
       "      <td>0.063247</td>\n",
       "      <td>0.143916</td>\n",
       "      <td>0.05825</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.862674</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date  activity_mean  circumplex.arousal_mean  \\\n",
       "0  AS14.01  2014-02-26       0.000000                   0.4375   \n",
       "1  AS14.01  2014-03-21       0.236766                   0.5500   \n",
       "2  AS14.01  2014-03-22       0.418390                   0.6500   \n",
       "3  AS14.01  2014-03-25       0.173753                   0.6250   \n",
       "4  AS14.01  2014-03-27       0.281736                   0.5500   \n",
       "\n",
       "   circumplex.valence_mean  mood_mean  appCat.builtin_sum  \\\n",
       "0                 0.615385   0.513158            0.000000   \n",
       "1                 0.446154   0.505263            0.077850   \n",
       "2                 0.538462   0.536842            0.018139   \n",
       "3                 0.538462   0.592105            0.025612   \n",
       "4                 0.630769   0.631579            0.030486   \n",
       "\n",
       "   appCat.communication_sum  appCat.entertainment_sum  appCat.finance_sum  \\\n",
       "0                  0.000000                  0.000000            0.000000   \n",
       "1                  0.303150                  0.028033            0.037502   \n",
       "2                  0.239538                  0.002597            0.015953   \n",
       "3                  0.496012                  0.001898            0.032589   \n",
       "4                  0.334794                  0.017790            0.031957   \n",
       "\n",
       "   ...  appCat.travel_sum_time_5  appCat.unknown_sum_time_5  \\\n",
       "0  ...                  0.000000                   0.000000   \n",
       "1  ...                  0.067479                   0.012146   \n",
       "2  ...                  0.070228                   0.012146   \n",
       "3  ...                  0.101173                   0.063247   \n",
       "4  ...                  0.034432                   0.063247   \n",
       "\n",
       "   appCat.utilities_sum_time_5  appCat.weather_sum_time_5  call_sum_time_5  \\\n",
       "0                     0.000000                    0.00000         0.123077   \n",
       "1                     0.138491                    0.00000         0.138462   \n",
       "2                     0.164772                    0.00000         0.184615   \n",
       "3                     0.256523                    0.05825         0.292308   \n",
       "4                     0.143916                    0.05825         0.184615   \n",
       "\n",
       "   screen_sum_time_5  sms_sum_time_5  day_time_5  weekDay_time_5  \\\n",
       "0           0.000000        0.152174    0.052727        0.625000   \n",
       "1           0.226449        0.065217    0.272727        0.416667   \n",
       "2           0.295118        0.065217    0.281818        0.625000   \n",
       "3           0.753727        0.043478    0.309091        0.666667   \n",
       "4           0.862674        0.043478    0.327273        0.500000   \n",
       "\n",
       "   mood_mean_TARGET  \n",
       "0          6.333333  \n",
       "1          6.400000  \n",
       "2          6.800000  \n",
       "3          6.600000  \n",
       "4          6.400000  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test[['id','date','mood_mean', 'mood_mean_TARGET']].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for name, group in dataset.groupby('id'):\n",
    "        x = list(group['mood_mean'])\n",
    "        y = list(group['mood_mean_TARGET'])\n",
    "        for i in range(len(group)-look_back):\n",
    "            dataX.append(x[i:(i+look_back)])\n",
    "            dataY.append(y[i + look_back-1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train[['id', 'mood_mean', 'mood_mean_TARGET']], look_back)\n",
    "testX, testY = create_dataset(test[['id', 'mood_mean', 'mood_mean_TARGET']], look_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "trainX = np.array([train['mood_mean']])\n",
    "trainY = np.array([train['mood_mean_TARGET']])\n",
    "\n",
    "testX = np.array([test['mood_mean']])\n",
    "testY = np.array([test['mood_mean_TARGET']])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(734, 1, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss: 28.6018\n",
      "Epoch 2/10\n",
      " - 1s - loss: 2.9142\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.6262\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.4522\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.4292\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.4222\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.4164\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.4130\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.4106\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.4089\n",
      "Time to train the model: 0.24 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.409 RMSE\n",
      "Test Score: 0.449 RMSE\n",
      "Time to predict: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# calculate root mean squared error\n",
    "#trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))\n",
    "trainScore = mean_squared_error(trainY, trainPredict[:,0])\n",
    "print('Train Score: %.3f MSE' % (trainScore))\n",
    "#testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))\n",
    "testScore = mean_squared_error(testY, testPredict[:,0])\n",
    "print('Test Score: %.3f MSE' % (testScore))\n",
    "\n",
    "print('Time to predict: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty df to save solutions\n",
    "solutionsTrain = pd.DataFrame(data={'id': [], 'date': [], 'mood_mean_target': [], 'predicted_mood_mean_target':[]})\n",
    "\n",
    "# Save solutions in df \n",
    "j = 0\n",
    "for name, group in train.groupby('id'):\n",
    "    for i in range(look_back-1, len(group)-1):\n",
    "        #print(j, i)\n",
    "        solutionsTrain = solutionsTrain.append({'id': group.iloc[i]['id'], 'date': group.iloc[i]['date'], 'mood_mean_target': group.iloc[i]['mood_mean_TARGET'],\n",
    "                                      'predicted_mood_mean_target': trainPredict[j]}, ignore_index=True)\n",
    "        j += 1   \n",
    "        \n",
    "\n",
    "# Create empty df to save solutions\n",
    "solutionsTest = pd.DataFrame(data={'id': [], 'date': [], 'mood_mean_target': [], 'predicted_mood_mean_target':[]})\n",
    "\n",
    "# Save solutions in df \n",
    "j = 0\n",
    "for name, group in test.groupby('id'):\n",
    "    for i in range(look_back-1, len(group)-1):\n",
    "        #print(j, i)\n",
    "        solutionsTest = solutionsTest.append({'id': group.iloc[i]['id'], 'date': group.iloc[i]['date'], 'mood_mean_target': group.iloc[i]['mood_mean_TARGET'],\n",
    "                                      'predicted_mood_mean_target': testPredict[j]}, ignore_index=True)\n",
    "        j += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### multi variate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset2(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for name, group in dataset.groupby('id'):\n",
    "        #define input sequences\n",
    "        in_seq1 = array(list(group['mood_mean']))\n",
    "        in_seq2 = array(list(group['circumplex.valence_mean']))\n",
    "        out_seq = array(list(group['mood_mean_TARGET']))\n",
    "        #out_seq = list(group['mood_mean_TARGET'])\n",
    "        #out_seq = array(out_seq[1:] + [np.nan])\n",
    "        \n",
    "        # convert to [rows, columns] structure\n",
    "        in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "        in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "        out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "        # horizontally stack columns\n",
    "        dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "        \n",
    "        for i in range(len(group)-look_back):\n",
    "            dataX.append(dataset[i:i+look_back, :-1])\n",
    "            dataY.append(dataset[i+look_back-1, -1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset2(train[['id', 'mood_mean', 'circumplex.valence_mean', 'mood_mean_TARGET']], look_back)\n",
    "testX, testY = create_dataset2(test[['id', 'mood_mean', 'circumplex.valence_mean', 'mood_mean_TARGET']], look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "734/734 [==============================] - 1s 1ms/step - loss: 48.4620\n",
      "Epoch 2/30\n",
      "734/734 [==============================] - 0s 118us/step - loss: 45.6161\n",
      "Epoch 3/30\n",
      "734/734 [==============================] - 0s 119us/step - loss: 40.4708\n",
      "Epoch 4/30\n",
      "734/734 [==============================] - 0s 116us/step - loss: 28.2171\n",
      "Epoch 5/30\n",
      "734/734 [==============================] - 0s 108us/step - loss: 6.3309\n",
      "Epoch 6/30\n",
      "734/734 [==============================] - 0s 110us/step - loss: 1.7063\n",
      "Epoch 7/30\n",
      "734/734 [==============================] - 0s 108us/step - loss: 1.3519\n",
      "Epoch 8/30\n",
      "734/734 [==============================] - 0s 108us/step - loss: 1.2618\n",
      "Epoch 9/30\n",
      "734/734 [==============================] - 0s 108us/step - loss: 1.2078\n",
      "Epoch 10/30\n",
      "734/734 [==============================] - 0s 109us/step - loss: 1.1549\n",
      "Epoch 11/30\n",
      "734/734 [==============================] - 0s 113us/step - loss: 1.0990\n",
      "Epoch 12/30\n",
      "734/734 [==============================] - 0s 109us/step - loss: 1.0465\n",
      "Epoch 13/30\n",
      "734/734 [==============================] - 0s 107us/step - loss: 0.9953\n",
      "Epoch 14/30\n",
      "734/734 [==============================] - 0s 110us/step - loss: 0.9401\n",
      "Epoch 15/30\n",
      "734/734 [==============================] - 0s 108us/step - loss: 0.8895\n",
      "Epoch 16/30\n",
      "734/734 [==============================] - 0s 110us/step - loss: 0.8342\n",
      "Epoch 17/30\n",
      "734/734 [==============================] - 0s 114us/step - loss: 0.7832\n",
      "Epoch 18/30\n",
      "734/734 [==============================] - 0s 114us/step - loss: 0.7338\n",
      "Epoch 19/30\n",
      "734/734 [==============================] - 0s 112us/step - loss: 0.6846\n",
      "Epoch 20/30\n",
      "734/734 [==============================] - 0s 110us/step - loss: 0.6488\n",
      "Epoch 21/30\n",
      "734/734 [==============================] - 0s 110us/step - loss: 0.6060\n",
      "Epoch 22/30\n",
      "734/734 [==============================] - 0s 108us/step - loss: 0.5584\n",
      "Epoch 23/30\n",
      "734/734 [==============================] - 0s 110us/step - loss: 0.5244\n",
      "Epoch 24/30\n",
      "734/734 [==============================] - 0s 109us/step - loss: 0.5090\n",
      "Epoch 25/30\n",
      "734/734 [==============================] - 0s 108us/step - loss: 0.4664\n",
      "Epoch 26/30\n",
      "734/734 [==============================] - 0s 110us/step - loss: 0.4487\n",
      "Epoch 27/30\n",
      "734/734 [==============================] - 0s 114us/step - loss: 0.4426\n",
      "Epoch 28/30\n",
      "734/734 [==============================] - 0s 114us/step - loss: 0.4313\n",
      "Epoch 29/30\n",
      "734/734 [==============================] - 0s 113us/step - loss: 0.4218\n",
      "Epoch 30/30\n",
      "734/734 [==============================] - 0s 108us/step - loss: 0.4217\n",
      "Time to train: 0.07 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(3, 2)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(trainX, trainY, epochs=30, verbose=1)\n",
    "\n",
    "print('Time to train: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "YhatsTrain = []\n",
    "for x in trainX:\n",
    "    x = x.reshape((1, 3, 2))\n",
    "    y = model.predict(x, verbose = 0)\n",
    "    YhatsTrain += [y[0][0]]\n",
    "\n",
    "YhatsTest = []\n",
    "for x in testX:\n",
    "    x = x.reshape((1, 3, 2))\n",
    "    y = model.predict(x, verbose = 0)\n",
    "    YhatsTest += [y[0][0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.451 MSE\n",
      "Test Score: 0.466 MSE\n"
     ]
    }
   ],
   "source": [
    "trainScore = mean_squared_error(trainY, YhatsTrain)\n",
    "print('Train Score: %.3f MSE' % (trainScore))\n",
    "testScore = mean_squared_error(testY, YhatsTest)\n",
    "print('Test Score: %.3f MSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty df to save solutions\n",
    "solutionsTrain = pd.DataFrame(data={'id': [], 'date': [], 'mood_mean_target': [], 'predicted_mood_mean_target':[]})\n",
    "\n",
    "# Save solutions in df \n",
    "j = 0\n",
    "for name, group in train.groupby('id'):\n",
    "    for i in range(look_back-1, len(group)-1):\n",
    "        #print(j, i)\n",
    "        solutionsTrain = solutionsTrain.append({'id': group.iloc[i]['id'], 'date': group.iloc[i]['date'], 'mood_mean_target': group.iloc[i]['mood_mean_TARGET'],\n",
    "                                      'predicted_mood_mean_target': YhatsTrain[j]}, ignore_index=True)\n",
    "        j += 1   \n",
    "        \n",
    "\n",
    "# Create empty df to save solutions\n",
    "solutionsTest = pd.DataFrame(data={'id': [], 'date': [], 'mood_mean_target': [], 'predicted_mood_mean_target':[]})\n",
    "\n",
    "# Save solutions in df \n",
    "j = 0\n",
    "for name, group in test.groupby('id'):\n",
    "    for i in range(look_back-1, len(group)-1):\n",
    "        #print(j, i)\n",
    "        solutionsTest = solutionsTest.append({'id': group.iloc[i]['id'], 'date': group.iloc[i]['date'], 'mood_mean_target': group.iloc[i]['mood_mean_TARGET'],\n",
    "                                      'predicted_mood_mean_target': YhatsTest[j]}, ignore_index=True)\n",
    "        j += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccMSQ(solutions, name_target,name_predicted):\n",
    "    correct = 0\n",
    "    squared_error = 0\n",
    "\n",
    "    for index, row in solutions.iterrows():\n",
    "        squared_error += math.pow(row[name_target]-row[name_predicted],2)\n",
    "        if (row[name_target] == row[name_predicted]):\n",
    "            correct = correct + 1\n",
    "        \n",
    "    accuracy = correct/ len(solutions.index)\n",
    "    msq = squared_error / len(solutions.index)\n",
    "    return accuracy, msq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "acc, msq: \n",
      "0.0 0.5415029766714039\n",
      "rmse:  0.7358688583378181\n",
      "acc, msq: \n",
      "0.5081743869209809 0.7029972752043597\n",
      "rmse:  0.83844932774996\n",
      " \n",
      "TEST\n",
      "acc, msq: \n",
      "0.0 0.5901747684184275\n",
      "rmse:  0.7682283309136858\n",
      "acc, msq: \n",
      "0.490625 0.71875\n",
      "rmse:  0.8477912478906585\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN\")\n",
    "accuracy, msq = calculateAccMSQ(solutionsTrain, \"mood_mean_target\", \"predicted_mood_mean_target\")\n",
    "print(\"acc, msq: \")\n",
    "print(accuracy, msq)\n",
    "print(\"rmse: \", math.sqrt(msq))\n",
    "\n",
    "solutionsTrain2 = solutionsTrain.round({'mood_mean_target': 0, 'predicted_mood_mean_target': 0})\n",
    "accuracy, msq = calculateAccMSQ(solutionsTrain2, \"mood_mean_target\", \"predicted_mood_mean_target\")\n",
    "print(\"acc, msq: \")\n",
    "print(accuracy, msq)\n",
    "print(\"rmse: \", math.sqrt(msq))\n",
    "\n",
    "print(\" \")\n",
    "print(\"TEST\")\n",
    "accuracy, msq = calculateAccMSQ(solutionsTest, \"mood_mean_target\", \"predicted_mood_mean_target\")\n",
    "print(\"acc, msq: \")\n",
    "print(accuracy, msq)\n",
    "print(\"rmse: \", math.sqrt(msq))\n",
    "\n",
    "solutionsTest2 = solutionsTest.round({'mood_mean_target': 0, 'predicted_mood_mean_target': 0})\n",
    "accuracy, msq = calculateAccMSQ(solutionsTest2, \"mood_mean_target\", \"predicted_mood_mean_target\")\n",
    "print(\"acc, msq: \")\n",
    "print(accuracy, msq)\n",
    "print(\"rmse: \", math.sqrt(msq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
