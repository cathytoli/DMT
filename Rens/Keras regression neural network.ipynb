{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"out_without_nan_mood_normalised.csv\")\n",
    "df['mood_mean_TARGET'] = df['mood_mean_TARGET'].astype(float)\n",
    "df = pd.concat([df,pd.get_dummies(df['id'])],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['weekDay'],prefix=\"day_\")],axis=1)\n",
    "df = df.drop(['weekDay_time_5','day_time_5','weekDay_time_4','day_time_4','weekDay_time_3','day_time_3','weekDay_time_2','day_time_2','weekDay_time_1','day_time_1','weekDay_time_5','circumplex.valence_mean_time_1'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'date' 'weekDay' 'circumplex.arousal_mean_time_1'\n",
      " 'appCat.builtin_sum_time_1' 'activity_mean_time_2'\n",
      " 'circumplex.valence_mean_time_2' 'appCat.travel_sum_time_2'\n",
      " 'appCat.weather_sum_time_2' 'appCat.social_sum_time_3'\n",
      " 'appCat.utilities_sum_time_3' 'appCat.builtin_sum_time_4'\n",
      " 'circumplex.arousal_mean_time_5' 'mood_mean_time_5'\n",
      " 'appCat.communication_sum_time_5' 'appCat.entertainment_sum_time_5'\n",
      " 'appCat.finance_sum_time_5' 'appCat.game_sum_time_5'\n",
      " 'appCat.office_sum_time_5' 'appCat.other_sum_time_5'\n",
      " 'appCat.unknown_sum_time_5' 'call_sum_time_5' 'sms_sum_time_5'\n",
      " 'lastTimeSeenMood_1' 'lastTimeSeenMood_2' 'lastTimeSeenMood_3'\n",
      " 'lastTimeSeenMood_4' 'lastTimeSeenMood_6' 'lastTimeSeenMood_7'\n",
      " 'lastTimeSeenMood_8' 'lastTimeSeenMood_9' 'mood_mean_TARGET'\n",
      " 'numberOfTimesSeenMood5Days_7' 'numberOfTimesSeenMood5Days_8' 'AS14.01'\n",
      " 'AS14.02' 'AS14.03' 'AS14.05' 'AS14.06' 'AS14.07' 'AS14.08' 'AS14.09'\n",
      " 'AS14.12' 'AS14.13' 'AS14.14' 'AS14.15' 'AS14.16' 'AS14.17' 'AS14.19'\n",
      " 'AS14.20' 'AS14.23' 'AS14.24' 'AS14.25' 'AS14.26' 'AS14.27' 'AS14.28'\n",
      " 'AS14.29' 'AS14.30' 'AS14.31' 'AS14.32' 'AS14.33' 'day__0.0'\n",
      " 'day__0.16666666666666666' 'day__0.3333333333333333' 'day__0.5'\n",
      " 'day__0.6666666666666666' 'day__0.8333333333333334' 'day__1.0']\n"
     ]
    }
   ],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (abs(corr_matrix.iloc[i, j]) >= threshold) and (corr_matrix.columns[j] not in col_corr) and corr_matrix.columns[i] != \"mood_mean_TARGET\" and corr_matrix.columns[j] != \"mood_mean_TARGET\":\n",
    "                \n",
    "                colnameI = corr_matrix.columns[i]\n",
    "                colnameJ = corr_matrix.columns[j]\n",
    "                if abs(corr_matrix.mood_mean_TARGET[colnameI]) > abs(corr_matrix.mood_mean_TARGET[colnameJ]):\n",
    "                    colname = colnameJ\n",
    "                else:\n",
    "                    colname = colnameI\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset\n",
    "    \n",
    "    return(dataset)\n",
    "newDF =df\n",
    "correlation(newDF,0.7)\n",
    "print(newDF.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df.corr()\n",
    "goodColumns= corr[abs(corr['mood_mean_TARGET'])>0.25]['mood_mean_TARGET'].sort_values()\n",
    "goodColumns = goodColumns.drop(['mood_mean_TARGET'])\n",
    "\n",
    "usedColumns = goodColumns.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AS14.07', 'lastTimeSeenMood_7', 'circumplex.valence_mean',\n",
       "       'circumplex.valence_mean_time_2', 'mood_mean', 'mood_mean_time_1',\n",
       "       'mood_mean_time_3', 'mood_mean_time_4', 'mood_mean_time_2',\n",
       "       'mood_mean_time_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usedColumns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "notRelevantAll=df.drop(['id','date'],axis=1).dropna()\n",
    "goldY= notRelevantAll['mood_mean_TARGET']\n",
    "relevant = notRelevantAll.drop(['mood_mean_TARGET'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(len(usedColumns), input_dim=len(usedColumns), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.16 (+/- 0.26)\n",
      "MSE: -0.41 (+/- 0.26)\n",
      "EXPLAINED VARIANCE: 0.18 (+/- 0.29)\n"
     ]
    }
   ],
   "source": [
    "scoring = {'R2': 'r2',\n",
    "           'Mean squared Error': 'neg_mean_squared_error',\n",
    "           'Explained variance': 'explained_variance'}\n",
    "\n",
    "scores = cross_validate(estimator, relevant[usedColumns], goldY, cv=7,scoring=scoring)\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores['test_R2'].mean(), scores['test_R2'].std() * 2))\n",
    "print(\"MSE: %0.2f (+/- %0.2f)\" % (scores['test_Mean squared Error'].mean(), scores['test_Mean squared Error'].std() * 2))\n",
    "print(\"EXPLAINED VARIANCE: %0.2f (+/- %0.2f)\" % (scores['test_Explained variance'].mean(), scores['test_Explained variance'].std() * 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
