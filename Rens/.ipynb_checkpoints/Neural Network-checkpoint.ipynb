{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rens\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"out_without_nan_mood_target.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mood back to whole numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df2\n",
    "df2['mood_mean_TARGET'] = df2['mood_mean_TARGET'].astype(float)\n",
    "dfNonNan = df2.dropna(subset = ['mood_mean_TARGET'] )\n",
    "dfNonNan = pd.concat([dfNonNan,pd.get_dummies(dfNonNan['id'])],axis=1)\n",
    "df['mood_mean_TARGET'] = df['mood_mean_TARGET'].astype(float).round().astype(str)\n",
    "df = pd.concat([df,pd.get_dummies(df['id'])],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only select columns with high correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AS14.07                           -0.264961\n",
      "AS14.12                           -0.195867\n",
      "weekDay_time_5                    -0.107756\n",
      "AS14.33                           -0.107082\n",
      "AS14.27                            0.100447\n",
      "appCat.entertainment_sum_time_1    0.104142\n",
      "appCat.entertainment_sum           0.104142\n",
      "appCat.other_sum_time_4            0.105976\n",
      "appCat.game_sum_time_3             0.108747\n",
      "activity_mean_time_3               0.109724\n",
      "appCat.entertainment_sum_time_3    0.112453\n",
      "activity_mean_time_1               0.112584\n",
      "activity_mean                      0.112584\n",
      "activity_mean_time_2               0.119888\n",
      "appCat.other_sum_time_5            0.121189\n",
      "appCat.game_sum_time_4             0.122164\n",
      "appCat.game_sum_time_5             0.123017\n",
      "appCat.entertainment_sum_time_4    0.123766\n",
      "appCat.entertainment_sum_time_5    0.130096\n",
      "AS14.32                            0.132730\n",
      "AS14.29                            0.142908\n",
      "AS14.03                            0.163754\n",
      "AS14.30                            0.211358\n",
      "circumplex.valence_mean_time_5     0.220753\n",
      "circumplex.valence_mean_time_3     0.223433\n",
      "circumplex.valence_mean_time_4     0.224724\n",
      "circumplex.valence_mean_time_1     0.250137\n",
      "circumplex.valence_mean            0.250137\n",
      "circumplex.valence_mean_time_2     0.251291\n",
      "mood_mean                          0.472047\n",
      "mood_mean_time_1                   0.472047\n",
      "mood_mean_time_3                   0.477074\n",
      "mood_mean_time_4                   0.486367\n",
      "mood_mean_time_5                   0.495198\n",
      "mood_mean_time_2                   0.496638\n",
      "Name: mood_mean_TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr=dfNonNan.corr()\n",
    "goodColumns= corr[abs(corr['mood_mean_TARGET'])>0.10]['mood_mean_TARGET'].sort_values()\n",
    "goodColumns = goodColumns.drop(['mood_mean_TARGET'])\n",
    "print(goodColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "notRelevantAll=df.drop(['id','date'],axis=1).dropna()\n",
    "goldY= notRelevantAll['mood_mean_TARGET']\n",
    "relevant = notRelevantAll.drop(['mood_mean_TARGET'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(relevant[goodColumns.keys()], goldY, test_size=0.33, random_state=42)\n",
    "y_train_cat = keras.utils.to_categorical(y_train.astype(float).astype(int))\n",
    "y_test_cat = keras.utils.to_categorical(y_test.astype(float).astype(int))\n",
    "\n",
    "goldY_train = keras.utils.to_categorical(goldY.astype(float).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(len(X_test.columns), activation='relu', input_shape=(len(X_test.columns),)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 35)                1260      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 288       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 1,638\n",
      "Trainable params: 1,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "814/814 [==============================] - 1s 1ms/step - loss: 1.3505 - acc: 0.4533\n",
      "Epoch 2/100\n",
      "814/814 [==============================] - 1s 705us/step - loss: 1.1616 - acc: 0.5061\n",
      "Epoch 3/100\n",
      "814/814 [==============================] - 1s 714us/step - loss: 1.1101 - acc: 0.5209\n",
      "Epoch 4/100\n",
      "814/814 [==============================] - 1s 682us/step - loss: 1.0863 - acc: 0.5467\n",
      "Epoch 5/100\n",
      "814/814 [==============================] - 1s 753us/step - loss: 1.0629 - acc: 0.5663\n",
      "Epoch 6/100\n",
      "814/814 [==============================] - 1s 788us/step - loss: 1.0491 - acc: 0.5614\n",
      "Epoch 7/100\n",
      "814/814 [==============================] - 1s 792us/step - loss: 1.0416 - acc: 0.5627\n",
      "Epoch 8/100\n",
      "814/814 [==============================] - 1s 679us/step - loss: 1.0360 - acc: 0.5676\n",
      "Epoch 9/100\n",
      "814/814 [==============================] - 1s 714us/step - loss: 1.0240 - acc: 0.5627\n",
      "Epoch 10/100\n",
      "814/814 [==============================] - 1s 675us/step - loss: 1.0206 - acc: 0.5774\n",
      "Epoch 11/100\n",
      "814/814 [==============================] - 1s 700us/step - loss: 1.0109 - acc: 0.5872\n",
      "Epoch 12/100\n",
      "814/814 [==============================] - 1s 723us/step - loss: 1.0083 - acc: 0.5663\n",
      "Epoch 13/100\n",
      "814/814 [==============================] - 1s 742us/step - loss: 1.0053 - acc: 0.5762\n",
      "Epoch 14/100\n",
      "814/814 [==============================] - 1s 718us/step - loss: 1.0093 - acc: 0.5627\n",
      "Epoch 15/100\n",
      "814/814 [==============================] - 1s 717us/step - loss: 1.0042 - acc: 0.5799\n",
      "Epoch 16/100\n",
      "814/814 [==============================] - 1s 700us/step - loss: 0.9890 - acc: 0.5860\n",
      "Epoch 17/100\n",
      "814/814 [==============================] - 1s 700us/step - loss: 0.9969 - acc: 0.5590\n",
      "Epoch 18/100\n",
      "814/814 [==============================] - 1s 934us/step - loss: 0.9912 - acc: 0.5725\n",
      "Epoch 19/100\n",
      "814/814 [==============================] - 1s 943us/step - loss: 0.9877 - acc: 0.5835\n",
      "Epoch 20/100\n",
      "814/814 [==============================] - 1s 841us/step - loss: 0.9910 - acc: 0.5774\n",
      "Epoch 21/100\n",
      "814/814 [==============================] - 1s 724us/step - loss: 0.9887 - acc: 0.5786\n",
      "Epoch 22/100\n",
      "814/814 [==============================] - 1s 701us/step - loss: 0.9880 - acc: 0.5897\n",
      "Epoch 23/100\n",
      "814/814 [==============================] - 1s 742us/step - loss: 0.9803 - acc: 0.5860\n",
      "Epoch 24/100\n",
      "814/814 [==============================] - 1s 690us/step - loss: 0.9850 - acc: 0.5897\n",
      "Epoch 25/100\n",
      "814/814 [==============================] - 1s 736us/step - loss: 0.9816 - acc: 0.5799\n",
      "Epoch 26/100\n",
      "814/814 [==============================] - 1s 730us/step - loss: 0.9812 - acc: 0.5934\n",
      "Epoch 27/100\n",
      "814/814 [==============================] - 1s 750us/step - loss: 0.9780 - acc: 0.5885\n",
      "Epoch 28/100\n",
      "814/814 [==============================] - 1s 717us/step - loss: 0.9695 - acc: 0.5860\n",
      "Epoch 29/100\n",
      "814/814 [==============================] - 1s 721us/step - loss: 0.9781 - acc: 0.5921\n",
      "Epoch 30/100\n",
      "814/814 [==============================] - 1s 731us/step - loss: 0.9647 - acc: 0.6007\n",
      "Epoch 31/100\n",
      "814/814 [==============================] - 1s 703us/step - loss: 0.9732 - acc: 0.5811\n",
      "Epoch 32/100\n",
      "814/814 [==============================] - 1s 798us/step - loss: 0.9726 - acc: 0.5799\n",
      "Epoch 33/100\n",
      "814/814 [==============================] - 1s 821us/step - loss: 0.9657 - acc: 0.5762\n",
      "Epoch 34/100\n",
      "814/814 [==============================] - 1s 742us/step - loss: 0.9699 - acc: 0.5872\n",
      "Epoch 35/100\n",
      "814/814 [==============================] - 1s 687us/step - loss: 0.9673 - acc: 0.6007\n",
      "Epoch 36/100\n",
      "814/814 [==============================] - 1s 828us/step - loss: 0.9606 - acc: 0.5995\n",
      "Epoch 37/100\n",
      "814/814 [==============================] - 1s 890us/step - loss: 0.9626 - acc: 0.5983\n",
      "Epoch 38/100\n",
      "814/814 [==============================] - 1s 693us/step - loss: 0.9539 - acc: 0.6032\n",
      "Epoch 39/100\n",
      "814/814 [==============================] - 1s 784us/step - loss: 0.9582 - acc: 0.5897\n",
      "Epoch 40/100\n",
      "814/814 [==============================] - 1s 796us/step - loss: 0.9572 - acc: 0.5921\n",
      "Epoch 41/100\n",
      "814/814 [==============================] - 1s 772us/step - loss: 0.9572 - acc: 0.5971\n",
      "Epoch 42/100\n",
      "814/814 [==============================] - 1s 741us/step - loss: 0.9561 - acc: 0.5995\n",
      "Epoch 43/100\n",
      "814/814 [==============================] - 1s 779us/step - loss: 0.9598 - acc: 0.5995\n",
      "Epoch 44/100\n",
      "814/814 [==============================] - 1s 735us/step - loss: 0.9569 - acc: 0.5799\n",
      "Epoch 45/100\n",
      "814/814 [==============================] - 1s 727us/step - loss: 0.9493 - acc: 0.6093\n",
      "Epoch 46/100\n",
      "814/814 [==============================] - 1s 753us/step - loss: 0.9620 - acc: 0.5983\n",
      "Epoch 47/100\n",
      "814/814 [==============================] - 1s 700us/step - loss: 0.9476 - acc: 0.5921\n",
      "Epoch 48/100\n",
      "814/814 [==============================] - 1s 729us/step - loss: 0.9494 - acc: 0.6093\n",
      "Epoch 49/100\n",
      "814/814 [==============================] - 1s 718us/step - loss: 0.9446 - acc: 0.6007\n",
      "Epoch 50/100\n",
      "814/814 [==============================] - 1s 720us/step - loss: 0.9473 - acc: 0.5934\n",
      "Epoch 51/100\n",
      "814/814 [==============================] - 1s 742us/step - loss: 0.9467 - acc: 0.5897\n",
      "Epoch 52/100\n",
      "814/814 [==============================] - 1s 791us/step - loss: 0.9449 - acc: 0.5860\n",
      "Epoch 53/100\n",
      "814/814 [==============================] - 1s 826us/step - loss: 0.9466 - acc: 0.6069\n",
      "Epoch 54/100\n",
      "814/814 [==============================] - 1s 730us/step - loss: 0.9343 - acc: 0.5971\n",
      "Epoch 55/100\n",
      "814/814 [==============================] - 1s 725us/step - loss: 0.9396 - acc: 0.5983\n",
      "Epoch 56/100\n",
      "814/814 [==============================] - 1s 724us/step - loss: 0.9377 - acc: 0.6032\n",
      "Epoch 57/100\n",
      "814/814 [==============================] - 1s 746us/step - loss: 0.9339 - acc: 0.6007\n",
      "Epoch 58/100\n",
      "814/814 [==============================] - 1s 931us/step - loss: 0.9347 - acc: 0.6081\n",
      "Epoch 59/100\n",
      "814/814 [==============================] - 1s 899us/step - loss: 0.9329 - acc: 0.6155\n",
      "Epoch 60/100\n",
      "814/814 [==============================] - 1s 846us/step - loss: 0.9421 - acc: 0.6007\n",
      "Epoch 61/100\n",
      "814/814 [==============================] - 1s 827us/step - loss: 0.9351 - acc: 0.6057\n",
      "Epoch 62/100\n",
      "814/814 [==============================] - 1s 846us/step - loss: 0.9339 - acc: 0.6007\n",
      "Epoch 63/100\n",
      "814/814 [==============================] - 1s 837us/step - loss: 0.9349 - acc: 0.6069\n",
      "Epoch 64/100\n",
      "814/814 [==============================] - 1s 828us/step - loss: 0.9291 - acc: 0.6155\n",
      "Epoch 65/100\n",
      "814/814 [==============================] - 1s 800us/step - loss: 0.9298 - acc: 0.6118\n",
      "Epoch 66/100\n",
      "814/814 [==============================] - 1s 739us/step - loss: 0.9280 - acc: 0.5971\n",
      "Epoch 67/100\n",
      "814/814 [==============================] - 1s 730us/step - loss: 0.9345 - acc: 0.6044\n",
      "Epoch 68/100\n",
      "814/814 [==============================] - 1s 775us/step - loss: 0.9289 - acc: 0.6057\n",
      "Epoch 69/100\n",
      "814/814 [==============================] - 1s 735us/step - loss: 0.9184 - acc: 0.6057\n",
      "Epoch 70/100\n",
      "814/814 [==============================] - 1s 733us/step - loss: 0.9202 - acc: 0.6179\n",
      "Epoch 71/100\n",
      "814/814 [==============================] - 1s 707us/step - loss: 0.9177 - acc: 0.6241\n",
      "Epoch 72/100\n",
      "814/814 [==============================] - 1s 792us/step - loss: 0.9187 - acc: 0.6081\n",
      "Epoch 73/100\n",
      "814/814 [==============================] - 1s 692us/step - loss: 0.9178 - acc: 0.6044\n",
      "Epoch 74/100\n",
      "814/814 [==============================] - 1s 864us/step - loss: 0.9212 - acc: 0.6069\n",
      "Epoch 75/100\n",
      "814/814 [==============================] - 1s 893us/step - loss: 0.9165 - acc: 0.5934\n",
      "Epoch 76/100\n",
      "814/814 [==============================] - 1s 742us/step - loss: 0.9226 - acc: 0.6057\n",
      "Epoch 77/100\n",
      "814/814 [==============================] - 1s 753us/step - loss: 0.9108 - acc: 0.6179\n",
      "Epoch 78/100\n",
      "814/814 [==============================] - 1s 741us/step - loss: 0.9121 - acc: 0.6069\n",
      "Epoch 79/100\n",
      "814/814 [==============================] - 1s 717us/step - loss: 0.9098 - acc: 0.6007\n",
      "Epoch 80/100\n",
      "814/814 [==============================] - 1s 742us/step - loss: 0.9132 - acc: 0.6081\n",
      "Epoch 81/100\n",
      "814/814 [==============================] - 1s 756us/step - loss: 0.9145 - acc: 0.6007\n",
      "Epoch 82/100\n",
      "814/814 [==============================] - 1s 728us/step - loss: 0.9038 - acc: 0.6057\n",
      "Epoch 83/100\n",
      "814/814 [==============================] - 1s 803us/step - loss: 0.9058 - acc: 0.6106\n",
      "Epoch 84/100\n",
      "814/814 [==============================] - 1s 824us/step - loss: 0.9079 - acc: 0.6106\n",
      "Epoch 85/100\n",
      "814/814 [==============================] - 1s 736us/step - loss: 0.9063 - acc: 0.6118\n",
      "Epoch 86/100\n",
      "814/814 [==============================] - 1s 767us/step - loss: 0.9084 - acc: 0.6192\n",
      "Epoch 87/100\n",
      "814/814 [==============================] - 1s 791us/step - loss: 0.8980 - acc: 0.6020\n",
      "Epoch 88/100\n",
      "814/814 [==============================] - 1s 828us/step - loss: 0.9011 - acc: 0.6093\n",
      "Epoch 89/100\n",
      "814/814 [==============================] - 1s 844us/step - loss: 0.8985 - acc: 0.6093\n",
      "Epoch 90/100\n",
      "814/814 [==============================] - 1s 784us/step - loss: 0.8960 - acc: 0.6069\n",
      "Epoch 91/100\n",
      "814/814 [==============================] - 1s 753us/step - loss: 0.9016 - acc: 0.6106\n",
      "Epoch 92/100\n",
      "814/814 [==============================] - 1s 728us/step - loss: 0.8944 - acc: 0.6081\n",
      "Epoch 93/100\n",
      "814/814 [==============================] - 1s 854us/step - loss: 0.9023 - acc: 0.6278\n",
      "Epoch 94/100\n",
      "814/814 [==============================] - 1s 846us/step - loss: 0.8952 - acc: 0.6229\n",
      "Epoch 95/100\n",
      "814/814 [==============================] - 1s 791us/step - loss: 0.8927 - acc: 0.6351\n",
      "Epoch 96/100\n",
      "814/814 [==============================] - 1s 742us/step - loss: 0.8916 - acc: 0.6290\n",
      "Epoch 97/100\n",
      "814/814 [==============================] - 1s 753us/step - loss: 0.8902 - acc: 0.6093\n",
      "Epoch 98/100\n",
      "814/814 [==============================] - 1s 687us/step - loss: 0.8881 - acc: 0.6253\n",
      "Epoch 99/100\n",
      "814/814 [==============================] - 1s 826us/step - loss: 0.8884 - acc: 0.6057\n",
      "Epoch 100/100\n",
      "814/814 [==============================] - 1s 657us/step - loss: 0.8875 - acc: 0.6241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12253b52fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model.fit(X_train, y_train_cat,epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 131us/step\n",
      "Test accuracy: 0.6044776125333795\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test_cat)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
